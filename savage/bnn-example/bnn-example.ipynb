{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3af9a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:17.421743Z",
     "start_time": "2024-11-19T23:34:16.656270Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import sympy\n",
    "import time\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from error_injection import MissingValueError, SamplingError, Injector\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.metrics import mutual_info_score, auc, roc_curve, roc_auc_score, f1_score\n",
    "from scipy.optimize import minimize as scipy_min\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.optimize import minimize, Bounds, linprog\n",
    "from sympy import Symbol as sb\n",
    "from sympy import lambdify\n",
    "from tqdm.notebook import trange,tqdm\n",
    "from IPython.display import display,clear_output\n",
    "from random import choice\n",
    "\n",
    "class style():\n",
    "    RED = '\\033[31m'\n",
    "    GREEN = '\\033[32m'\n",
    "    BLUE = '\\033[34m'\n",
    "    RESET = '\\033[0m'\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b5d2a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:17.779093Z",
     "start_time": "2024-11-19T23:34:17.774961Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce4f44b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:18.398577Z",
     "start_time": "2024-11-19T23:34:18.377783Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_mpg():\n",
    "    # fetch dataset\n",
    "    auto_mpg = pd.read_csv('auto-mpg.csv').drop('car name', axis=1).replace('?', np.nan)\n",
    "    \n",
    "    features = ['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "                'acceleration', 'model year', 'origin']\n",
    "    X = auto_mpg[features].astype(float)\n",
    "    y = auto_mpg['mpg']\n",
    "    \n",
    "    # with this random seed, no null value is included in the test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    X_train = copy.deepcopy(X_train).reset_index(drop=True)\n",
    "    X_test = copy.deepcopy(X_test).reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# first impute the data and make it hypothetically clean\n",
    "def load_mpg_cleaned():\n",
    "    # fetch dataset\n",
    "    auto_mpg = pd.read_csv('auto-mpg.csv').drop('car name', axis=1).replace('?', np.nan)\n",
    "    \n",
    "    features = ['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "                'acceleration', 'model year', 'origin']\n",
    "    X = auto_mpg[features].astype(float)\n",
    "    y = auto_mpg['mpg']\n",
    "    \n",
    "    # assumed gt imputation\n",
    "    imputer = KNNImputer(n_neighbors=10)\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    X_train = copy.deepcopy(X_train).reset_index(drop=True)\n",
    "    X_test = copy.deepcopy(X_test).reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902e7486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:18.909111Z",
     "start_time": "2024-11-19T23:34:18.883943Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_mpg_cleaned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d70c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:19.330193Z",
     "start_time": "2024-11-19T23:34:19.299108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2065.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>8.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3892.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>6.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3288.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement  horsepower  weight  acceleration  model year  \\\n",
       "0          8.0         350.0       125.0  3900.0          17.4        79.0   \n",
       "1          8.0         455.0       225.0  3086.0          10.0        70.0   \n",
       "2          4.0          91.0        68.0  2025.0          18.2        82.0   \n",
       "3          4.0         122.0        86.0  2226.0          16.5        72.0   \n",
       "4          4.0          97.0        67.0  2065.0          17.8        81.0   \n",
       "..         ...           ...         ...     ...           ...         ...   \n",
       "313        4.0         140.0        86.0  2790.0          15.6        82.0   \n",
       "314        4.0         140.0        88.0  2720.0          15.4        78.0   \n",
       "315        8.0         304.0       150.0  3892.0          12.5        72.0   \n",
       "316        4.0          97.0        75.0  2265.0          18.2        77.0   \n",
       "317        6.0         232.0       100.0  3288.0          15.5        71.0   \n",
       "\n",
       "     origin  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       3.0  \n",
       "3       1.0  \n",
       "4       3.0  \n",
       "..      ...  \n",
       "313     1.0  \n",
       "314     1.0  \n",
       "315     1.0  \n",
       "316     3.0  \n",
       "317     1.0  \n",
       "\n",
       "[318 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8c3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T21:50:31.706218Z",
     "start_time": "2024-05-08T21:50:31.581473Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667a9d92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:20.246232Z",
     "start_time": "2024-11-19T23:34:20.207546Z"
    },
    "code_folding": [
     3,
     27,
     71,
     104,
     125,
     150
    ]
   },
   "outputs": [],
   "source": [
    "# useful functions\n",
    "\n",
    "symbol_id = -1\n",
    "def create_symbol(suffix=''):\n",
    "    global symbol_id\n",
    "    symbol_id += 1\n",
    "    name = f'e{symbol_id}_{suffix}' if suffix else f'e{symbol_id}'\n",
    "    return sympy.Symbol(name=name)\n",
    "\n",
    "\n",
    "scaler_symbols = set([sb(f'k{i}') for i in range(X_train.shape[1]+1)])\n",
    "linearization_dict = dict()\n",
    "reverse_linearization_dict = dict()\n",
    "\n",
    "\n",
    "def sample_data(imputed_datasets, uncert_inds=[], seed=42):\n",
    "    imp_np = np.array(imputed_datasets)\n",
    "    if len(uncert_inds) == 0:\n",
    "        uncert_inds = list(itertools.product(range(imp_np.shape[1]),range(imp_np.shape[2])))\n",
    "    np.random.seed(seed)\n",
    "    choices = np.random.choice(np.arange(imp_np.shape[0]), len(uncert_inds), replace=True)\n",
    "    sample_result = imputed_datasets[0].copy()\n",
    "    for i, ind in enumerate(uncert_inds):\n",
    "        sample_result[ind[0]][ind[1]] = imputed_datasets[choices[i]][ind[0]][ind[1]]\n",
    "    return sample_result\n",
    "\n",
    "\n",
    "def linearization(expr_ls):\n",
    "    processed_expr_ls = [0 for _ in range(len(expr_ls))]\n",
    "    for expr_id, expr in enumerate(expr_ls):\n",
    "        # Do not support monomial expr currently, e.g., expr = 1.5*e1. \n",
    "        # At lease two monomials in expr, e.g., expr = 1.5*e1 + 2.\n",
    "        if not(expr.free_symbols):\n",
    "            processed_expr_ls[expr_id] += expr\n",
    "            continue\n",
    "        expr = expr.expand()\n",
    "        for arg in expr.args:\n",
    "            if not(arg.free_symbols):\n",
    "                processed_expr_ls[expr_id] += arg\n",
    "                continue\n",
    "            p = arg.as_poly()\n",
    "            monomial_exponents = p.monoms()[0]\n",
    "            \n",
    "            # only deal with non-linear monomials (order > 2)\n",
    "            if sum(monomial_exponents) <= 1:\n",
    "                processed_expr_ls[expr_id] += arg\n",
    "                continue\n",
    "\n",
    "            monomial = sympy.prod(x**k for x, k in zip(p.gens, monomial_exponents) \n",
    "                                  if not(x in scaler_symbols))\n",
    "            # check global substitution dictionary\n",
    "            if monomial in linearization_dict:\n",
    "                processed_expr_ls[expr_id] += arg.coeff(monomial)*linearization_dict[monomial]\n",
    "            else:\n",
    "                found = False\n",
    "                subs_monomial = create_symbol()\n",
    "                for symb in monomial.free_symbols:\n",
    "                    if symb in reverse_linearization_dict:\n",
    "                        equivalent_monomial = monomial.subs(symb, reverse_linearization_dict[symb])\n",
    "                        if equivalent_monomial in linearization_dict:\n",
    "                            subs_monomial = linearization_dict[equivalent_monomial]\n",
    "                            found = True\n",
    "                            break\n",
    "                linearization_dict[monomial] = subs_monomial\n",
    "                if not(found):\n",
    "                    reverse_linearization_dict[subs_monomial] = monomial\n",
    "                processed_expr_ls[expr_id] += arg.coeff(monomial)*subs_monomial\n",
    "                \n",
    "    return processed_expr_ls\n",
    "\n",
    "\n",
    "def merge_small_components_pca(expr_ls, budget=10):\n",
    "    if not(isinstance(expr_ls, sympy.Expr)):\n",
    "        expr_ls = sympy.Matrix(expr_ls)\n",
    "    if expr_ls.free_symbols:\n",
    "        center = expr_ls.subs(dict([(symb, 0) for symb in expr_ls.free_symbols]))\n",
    "    else:\n",
    "        return expr_ls\n",
    "    monomials_dict = get_generators(expr_ls)\n",
    "    generators = np.array([monomials_dict[m] for m in monomials_dict])\n",
    "    if len(generators) <= budget:\n",
    "        return expr_ls\n",
    "    monomials = [m for m in monomials_dict]\n",
    "    pca = PCA(n_components=len(generators[0]))\n",
    "    pca.fit(np.concatenate([generators, -generators]))\n",
    "    transformed_generators = pca.transform(generators)\n",
    "    transformed_generator_norms = np.linalg.norm(transformed_generators, axis=1, ord=2)\n",
    "    # from largest to lowest norm\n",
    "    sorted_indices = transformed_generator_norms.argsort()[::-1].astype(int)\n",
    "    sorted_transformed_generators = transformed_generators[sorted_indices]\n",
    "    sorted_monomials = [monomials[idx] for idx in sorted_indices]\n",
    "    new_transformed_generators = np.concatenate([sorted_transformed_generators[:budget], \n",
    "                                                 np.diag(np.sum(np.abs(sorted_transformed_generators[budget:]), \n",
    "                                                                axis=0))])\n",
    "    new_generators = pca.inverse_transform(new_transformed_generators)\n",
    "    new_monomials = sorted_monomials[:budget] + [create_symbol() for _ in range(len(generators[0]))]\n",
    "    \n",
    "    processed_expr_ls = center\n",
    "    for monomial_id in range(len(new_monomials)):\n",
    "        processed_expr_ls += sympy.Matrix(new_generators[monomial_id])*new_monomials[monomial_id]\n",
    "    \n",
    "    return processed_expr_ls\n",
    "\n",
    "\n",
    "def get_vertices(affset):\n",
    "    l = len(affset)\n",
    "    distinct_symbols = set()\n",
    "    for expr in affset:\n",
    "        if not(isinstance(expr, sympy.Expr)):\n",
    "            assert isinstance(expr, int) or isinstance(expr, float)\n",
    "        else:\n",
    "            if distinct_symbols:\n",
    "                distinct_symbols = distinct_symbols.union(expr.free_symbols)\n",
    "            else:\n",
    "                distinct_symbols = expr.free_symbols\n",
    "    distinct_symbols = list(distinct_symbols)\n",
    "    # print(distinct_symbols)\n",
    "    combs = [list(zip(distinct_symbols,list(l))) for l in list(itertools.product([-1, 1], repeat=len(distinct_symbols)))]\n",
    "    res = set()\n",
    "    for assignment in combs:\n",
    "        res.add(tuple([expr.subs(assignment) for expr in affset]))\n",
    "    return(res)\n",
    "\n",
    "\n",
    "# take a list of expressions as input, output the list of monomials and generator vectors,\n",
    "def get_generators(expr_ls):\n",
    "    monomials = dict()\n",
    "    for expr_id, expr in enumerate(expr_ls):\n",
    "        if not(isinstance(expr, sympy.Expr)) or not(expr.free_symbols):\n",
    "            continue\n",
    "        expr = expr.expand()\n",
    "        p = sympy.Poly(expr)\n",
    "        monomials_in_expr = [sympy.prod(x**k for x, k in zip(p.gens, mon)) \n",
    "                             for mon in p.monoms() if sum(mon) >= 1]\n",
    "        for monomial in monomials_in_expr:\n",
    "            coef = float(p.coeff_monomial(monomial))\n",
    "            if monomial in monomials:\n",
    "                if len(monomials[monomial]) < expr_id:\n",
    "                    monomials[monomial] = monomials[monomial] + [0 for _ in range(expr_id-len(monomials[monomial]))]\n",
    "                monomials[monomial].append(coef)\n",
    "            else:\n",
    "                monomials[monomial] = [0 for _ in range(expr_id)] + [coef]\n",
    "\n",
    "    for monomial in monomials:\n",
    "        if len(monomials[monomial]) < len(expr_ls):\n",
    "            monomials[monomial] = monomials[monomial] + [0 for _ in range(len(expr_ls)-len(monomials[monomial]))]\n",
    "    \n",
    "    return monomials\n",
    "\n",
    "\n",
    "def plot_conretiztion(affset, alpha = 0.5, color='red', budget=-1):\n",
    "    if budget > -1:\n",
    "        affset = merge_small_components_pca(affset, budget=budget)\n",
    "    pts = np.array(list(map(list, get_vertices(affset))))\n",
    "    hull = ConvexHull(pts)\n",
    "    plt.fill(pts[hull.vertices,0], pts[hull.vertices,1],color,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f19a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:20.953066Z",
     "start_time": "2024-11-19T23:34:20.935415Z"
    },
    "code_folding": [
     33
    ]
   },
   "outputs": [],
   "source": [
    "def inject_ranges(X, y, uncertain_attr, uncertain_num, uncertain_radius_pct=None, \n",
    "                  uncertain_radius=None, seed=42):\n",
    "    global symbol_id\n",
    "    symbol_id = -1\n",
    "    \n",
    "    X_extended = np.append(np.ones((len(X), 1)), X, axis=1)\n",
    "    ss = StandardScaler()\n",
    "    X_extended[:, 1:] = ss.fit_transform(X_extended[:, 1:])\n",
    "    X_extended_symb = sympy.Matrix(X_extended)\n",
    "    \n",
    "    if not(uncertain_attr=='y'):\n",
    "        uncertain_attr_idx = X.columns.to_list().index(uncertain_attr) + 1\n",
    "        if not(uncertain_radius):\n",
    "            uncertain_radius = uncertain_radius_pct*(np.max(X_extended[:, uncertain_attr_idx])-\\\n",
    "                                                     np.min(X_extended[:, uncertain_attr_idx]))\n",
    "    else:\n",
    "        if not(uncertain_radius):\n",
    "            uncertain_radius = uncertain_radius_pct*(y_train.max()-y_train.min())[0]\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    uncertain_indices = np.random.choice(range(len(y)), uncertain_num, replace=False)\n",
    "    y_symb = sympy.Matrix(y)\n",
    "    symbols_in_data = set()\n",
    "    for uncertain_idx in uncertain_indices:\n",
    "        new_symb = create_symbol()\n",
    "        symbols_in_data.add(new_symb)\n",
    "        if uncertain_attr=='y':\n",
    "            y_symb[uncertain_idx] = y_symb[uncertain_idx] + uncertain_radius*new_symb\n",
    "        else:\n",
    "            X_extended_symb[uncertain_idx, uncertain_attr_idx] = X_extended_symb[uncertain_idx, uncertain_attr_idx] + uncertain_radius*new_symb\n",
    "    return X_extended_symb, y_symb, symbols_in_data, ss\n",
    "\n",
    "\n",
    "def sample_data_from_ranges(X, y, seed=42):\n",
    "    all_free_symbols = X.free_symbols.union(y.free_symbols)\n",
    "    subs_dict = dict()\n",
    "    np.random.seed(seed)\n",
    "    for symb in all_free_symbols:\n",
    "        subs_dict[symb] = (np.random.uniform()-.5)*2\n",
    "    return X.subs(subs_dict), y.subs(subs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c424231",
   "metadata": {},
   "source": [
    "### BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7214e6f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:34:22.568106Z",
     "start_time": "2024-11-19T23:34:21.843049Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchbnn as bnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e3bc46b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:40:26.602554Z",
     "start_time": "2024-11-19T23:40:26.483738Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# get uncertain data\n",
    "uncertain_attr = 'weight'\n",
    "uncertain_num = int(len(X_train) * 0.1)\n",
    "uncertain_radius_pct = 0.1\n",
    "seed = 0\n",
    "\n",
    "X, y, symbols_in_data, ss = inject_ranges(X=X_train, y=y_train, uncertain_attr=uncertain_attr, \n",
    "                                          uncertain_num=uncertain_num, \n",
    "                                          uncertain_radius_pct=uncertain_radius_pct, \n",
    "                                          seed=seed)\n",
    "n = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e70eef46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:40:26.949778Z",
     "start_time": "2024-11-19T23:40:26.917522Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "X_train_expanded = np.append(np.ones((len(X_train), 1)), ss.transform(X_train), axis=1)\n",
    "X_test_expanded = np.append(np.ones((len(X_test), 1)), ss.transform(X_test), axis=1)\n",
    "actual_model = np.matmul(np.matmul(np.linalg.inv(np.matmul(X_train_expanded.T, X_train_expanded)), \n",
    "                                   X_train_expanded.T), y_train)\n",
    "y_test_pred = np.matmul(X_test_expanded, actual_model.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e7f81b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:40:45.797474Z",
     "start_time": "2024-11-19T23:40:27.246917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43513201ea749c2a0f25e865685a055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- MSE : 11.94, KL : 1743.64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5191aba4d54f61934b270720649031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- MSE : 11.80, KL : 1739.59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12121f88c4d24e59bc7b1abcf2b1a58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- MSE : 12.06, KL : 1738.19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "\n",
    "coverages = []\n",
    "avg_bands = []\n",
    "\n",
    "# The next few rows about adding nan could be replaced with the error injection function of the framework\n",
    "X_train_nan = X_train.copy()\n",
    "# X: the training data with missing values replaced with ranges in the inject_ranges function\n",
    "# goal: convert those ranges back to np.nan\n",
    "for i in range(len(X[:, 4])):\n",
    "    # having error symbol, meaning that this entry is missing\n",
    "    if X[i, 4].free_symbols:\n",
    "        X_train_nan[i, 4] = np.nan\n",
    "\n",
    "\n",
    "imputers = [KNNImputer(n_neighbors=5), KNNImputer(n_neighbors=10), IterativeImputer(random_state=0)]\n",
    "\n",
    "for seed, imputer in enumerate(imputers):\n",
    "    x_samp = ss.transform(imputer.fit_transform(X_train_nan))\n",
    "    y_samp = np.array(y.tolist()).astype(float)\n",
    "    x_samp, y_samp = sample_data_from_ranges(X, y, seed=seed)\n",
    "    x_samp = torch.FloatTensor(x_samp.tolist())\n",
    "    y_samp = torch.FloatTensor(y_samp.tolist())\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=X.shape[1], out_features=1),\n",
    "    )\n",
    "    mse_loss = nn.MSELoss()\n",
    "    kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "    kl_weight = 0.001\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    mses = []\n",
    "    # large enough for ensuring convergence\n",
    "    for step in tqdm(range(5000)):\n",
    "        pre = model(x_samp)\n",
    "        mse = mse_loss(pre, y_samp)\n",
    "        kl = kl_loss(model)\n",
    "        cost = mse + kl_weight*kl\n",
    "        mses.append(float(mse.detach().numpy()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('- MSE : %2.2f, KL : %2.2f' % (mse.item(), kl.item()))\n",
    "    \n",
    "    test_preds = []\n",
    "    X_test_expanded = np.append(np.ones((len(X_test), 1)), ss.transform(X_test), axis=1)\n",
    "    for sample_id in range(1000):\n",
    "        torch.manual_seed(sample_id*(seed+1))\n",
    "        test_pred = model(torch.FloatTensor(X_test_expanded)).detach().numpy().ravel()\n",
    "        test_preds.append(test_pred)\n",
    "\n",
    "    test_pred_mins = np.min(test_preds, axis=0)\n",
    "    test_pred_maxs = np.max(test_preds, axis=0)\n",
    "\n",
    "    coverages.append(np.mean((y_test_pred<=test_pred_maxs)&(y_test_pred>=test_pred_mins)))\n",
    "    avg_bands.append(np.mean(test_pred_maxs-test_pred_mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "423473e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T23:40:45.801039Z",
     "start_time": "2024-11-19T23:40:45.798694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9625, 0.825, 0.925], [0.598289, 0.55078244, 0.55372745])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverages, avg_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08859f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
